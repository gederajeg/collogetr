% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/utils.R
\name{tokenising}
\alias{tokenising}
\title{Tokenising the Leipzig Corpora}
\usage{
tokenising(corpus = NULL, split_pattern = NULL, lower_case = NULL,
  corpus_names = NULL)
}
\arguments{
\item{corpus}{A character vector of corpus sentences.}

\item{split_pattern}{A regular expression for how the corpus to be split.
It is passed on from \code{split_corpus_regex} argument of \code{colloc_leipzig}.}

\item{lower_case}{Logical; whether to lower case the tokenised items or not.
It is passed on from \code{to_lower_colloc} argument of \code{colloc_leipzig}.}

\item{corpus_names}{Name of the corpus file being processed.}
}
\value{
A large character vector of word-tokens.
}
\description{
Utility function to tokenise the input corpus of sentences into word vector.
    It is called internally by \code{colloc_leipzig}.
}
