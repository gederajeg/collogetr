---
output:
  github_document:
    html_preview: false
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

**Authors:** [Gede Primahadi Wijaya Rajeg](https://figshare.com/authors/Gede_Primahadi_Wijaya_Rajeg/1234749)<br/>
**License:** [GPL-2](https://www.gnu.org/licenses/old-licenses/gpl-2.0.en.html)<br/>

[![Travis-CI Build Status](https://travis-ci.org/gederajeg/collogetr.svg?branch=master)](https://travis-ci.org/gederajeg/collogetr)<br/>
[![Coverage Status](https://img.shields.io/codecov/c/github/gederajeg/collogetr/master.svg)](https://codecov.io/github/gederajeg/collogetr?branch=master)


```{r, echo = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "README-"
)
scaps <- function(concept) {
  paste("<span style='font-variant:small-caps;'>", concept, "</span>", sep="")
}
```

# collogetr

The goal of collogetr is to perform window-span collocates retrieval from the sentence-based corpus of the (Indonesian) [Leipzig Corpora](http://wortschatz.uni-leipzig.de/en/download). It is powered by most of the core packages from the [tidyverse](https://www.tidyverse.org). The initial purpose of this package was to help me with my [PhD thesis](http://rpubs.com/primahadi/ca_3d_metaphor_happiness_synonyms_Indonesian) on `r scaps("happiness")` metaphors in Indonesian based on data from the Leipzig Corpora.

This package is under development. Currently, there is one function available for retrieving the collocates (i.e., `colloc_leipzig()`) and two other functions to prepare data (i.e., `assoc_prepare()`) and then perform association measure of collocates with the node-word as in the [collostructional/collocation analysis](http://www.linguistics.ucsb.edu/faculty/stgries/teaching/groningen/index.html) (i.e., `collex_fye()`). Future plan is to include other function for generating non-Leipzig, sentence-based corpus inputs. The development version of the package can be installed via GitHub with [devtools](https://github.com/hadley/devtools):

```{r eval = FALSE}
library(devtools)
install_github("gederajeg/collogetr")
```


## Example for retrieving the collocates with `colloc_leipzig()`.

The following code shows how to use `colloc_leipzig()` to search for the collocates for the future marker *ke* 'to' in Indonesian. The function will print out progress messages for steps taken. The input corpus below (i.e. `demo_corpus_leipzig`) is included as data in this package whose documentation can be accessed via `?demo_corpus_leipzig`.

```{r example, eval = TRUE}
library(collogetr)
out <- colloc_leipzig(leipzig_corpus_list = demo_corpus_leipzig[2:3],
                       pattern = "\\bke\\b",
                       window = "r",
                       span = 1,
                       save_interim = FALSE)
```

The collocates are restricted to those occurring one-word to the right of *ke* (i.e., its R1 collocates). The window direction and span are respectively specified in the `window` and `span` arguments. The `"r"` character in `window` stands for 'right'-side collocates (`"l"` for 'left'-side collocates and `"b"` for both right- and left-side collocates). The `span` argument requires integer to indicate the range of words covered in the specified window. The `pattern` argument requires regular expression input. `colloc_leipzig()` accept two kinds of corpus-input. First, a named-list object with character-vector elements of each Leipzig Corpus Files. The format of this kind of input is shown below.

```{r leipzig_list_input}
lapply(demo_corpus_leipzig[2:3], sample, 3)
```

The second input is full-path to the Leipzig Corpus Files saved as UTF-8 encoded plain-texts. If this kind of input is preferred, supply the path to the `leipzig_path` argument; the `leipzig_corpus_list` will be by default set with `NULL`.

## Exploring the output of `colloc_leipzig()`.

The output of `colloc_leipzig()` is a list of `r length(out)` elements.

```{r colloc_output}
str(out)
```

The first is `collocs_df` that is a tibble of raw collocates data, that is, not yet counted for their frequencies. The frequencies of the collocates are stored in the second element, namely `collocs_freq`. The `words_freq` element consist of frequency list of all word-tokens in the loaded corpus. This frequencly-list data (and the `all_corpus_size` data), is included for the development of this function to include functions to perform collocational strength measure for the search pattern with the collocates (i.e., `collex_fye()`; cf. below).

```{r colloc_freq_output}
# top-10 most frequent collocates in the sample corpus
out$collocs_freq[1:10,]
```

## Performing association measure (i.e., *Collexeme Analysis*) with `collex_fye()`.

There are two available functions for the purpose of *Collexeme Analysis* with this package. The first one is `assoc_prepare()`. This function prepares the data (i.e., the output of `colloc_leipzig()`) into a tidy format required to perform the association measure (with `collex_fye()`), including calculating the expected co-occurrence frequencies between the collocates/collexemes and the node-word/construction. As in the Collostructional Analysis (cf. Stefanowitsch and Gries, [2003](http://www.linguistics.ucsb.edu/faculty/stgries/research/2003_AS-STG_Collostructions_IJCL.pdf)), the measure uses one-tailed *Fisher-Yates Exact* test whose *p*-~fisher~value is log-transformed to the base of 10 to indicate the collostruction strength between the collocates and the node word/construction (cf., e.g., Gries, Hampe, and SchÃ¶nefeld, [2005](http://www.linguistics.ucsb.edu/faculty/stgries/research/2005_STG-BH-DS_CollStr-vs-Freq_CogLing.pdf), *inter alia*). `collex_fye()` simultaneously performs two uni-directional measures of *Delta P*, one in which the extent to which the presence of the node-word/construction cues the collocates/collexemes, and *vice versa*. 

The `assoc_prepare()` and `collex_fye()` functions are designed following the tidy principle so that the association measure is performed in a row-wise fashion, benefiting from the combination of [*nested* column](http://r4ds.had.co.nz/many-models.html#list-columns-1) for the input-data (using `tidyr::nest()`) and `purrr`'s `map_*` function.

The following chunk illustrates the retrieval of right-side collocates of future marker *akan* 'will/be going to' in Indonesian and the use of `assoc_prepare()` to generate the input-data for the association measure of the collocates with *akan*.

```{r example-fye, message = FALSE}
# search the collocates
out <- colloc_leipzig(leipzig_corpus_list = demo_corpus_leipzig,
                       pattern = "\\bakan\\b",
                       window = "r",
                       span = 3,
                       save_interim = FALSE)

# prepare the input data; stopwords list are included in the package
assoc_tb <- assoc_prepare(colloc_out = out, stopword_list = stopwords)

# peek into the assoc_tb
head(assoc_tb, 3)
```

The column `data` in `assoc_tb` consists of nested tibble/table as a list. Each contains required data for performing association measure for each of the collocates in column `w`. This nested column can be inspected as follows (for the first row, i.e. for the word *menjadi* 'to become').

```{r inspect-nested-column}
# get the tibble in the `data` column for the first row
assoc_tb$data[[1]]
```

Then, we can perform the Collexeme Analysis as follows with `assoc_tb` as the input for the `df` argument. The output is sorted in descending order of the Collostruction Strength (in the `collstr` column).

```{r perform-fye}
# perform FYE test for Collexeme Analysis
am_fye <- collex_fye(df = assoc_tb, collstr_digit = 3)

# get the top-15 most strongly attracted collocates
dplyr::top_n(am_fye, 15, collstr)
```

The following code can be used to retrieved collocates that occur less frequently than expected (or in *repulsion* association).

```{r fye-repulsion}
dplyr::filter(am_fye, assoc == "repulsion")
```

Future development is to include a function to perform *Distinctive Collocates/Collexemes* analysis (cf. Gries and Stefanowitsch, [2004](http://www.linguistics.ucsb.edu/faculty/stgries/research/2004_STG-AS_ExtendingCollostructions_IJCL.pdf)), and other association measures using different statistics (e.g., *X*^2^, or log-likelihood ratio).
